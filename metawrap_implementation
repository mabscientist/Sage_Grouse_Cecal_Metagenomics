#Metawrap 1.3.2 Pipeline Implementation Example with Sage-Grouse Metagenomics Dataset
#MAB 7/26/21 
#
#N.B. the components of this script are meant to be run independently, not as one unit
#Additional configurations to conda environment may be needed.
#For tutorial example, see https://github.com/bxlab/metaWRAP/blob/master/Usage_tutorial.md
#
##################################################################################################################################################################

#INTRODUCTION
#upload raw .fastq.gz into this directory in format _1.fastq.gz and _2.fastq.gz format (forward and reverse)
#directory=sage_grouse2; directories for each step within this

#an environment with the latest metawrap installed should be activated when running these commands
conda create -y -n metawrap-env python=2.7
conda activate metawrap-env
conda config --add channels defaults
conda config --add channels conda-forge
conda config --add channels bioconda
conda config --add channels ursky
conda install -y -c ursky metawrap-mg

#READ_QC
#download reference genome (GCA_005890655.1_Cmin_1.0_genomic.fna.gz) for removing host DNA contamination and configure; run trimming for host DNA and quality

#configure reference genome
mkdir BMTAGGER_INDEX/
mv GCA_005890655.1_Cmin_1.0_genomic.fna.gz BMTAGGER_INDEX/
gunzip GCA_005890655.1_Cmin_1.0_genomic.fna.gz
mv GCA_005890655.1_Cmin_1.0_genomic.fna Cmin.fna
bmtool -d Cmin.fna -o Cmin.bitmask
srprism mkindex -i Cmin.fna -o Cmin.srprism -M 100000

#N.B. Modify the path in the metawrap config file 
#vim ~/.conda/envs/metawrap-env/bin/config-metawrap:
#insert: BMTAGGER_DB=/data/grouse_shotgun/sage_grouse2/BMTAGGER_INDEX

#actually run READ_QC
mkdir READ_QC
for F in RAW_READS/*_1.fastq.gz; do 
	R=${F%_*}_2.fastq.gz
	BASE=${F##*/}
	SAMPLE=${BASE%_*}
	nohup metawrap read_qc -1 $F -2 $R -x Cmin -t 8 -o READ_QC/$SAMPLE &
done	

#Move quality controlled, trimmed reads to separate directory:
mkdir CLEAN_READS
for i in READ_QC/*; do 
	b=${i#*/}
	mv ${i}/final_pure_reads_1.fastq CLEAN_READS/${b}_1.fastq
	mv ${i}/final_pure_reads_2.fastq CLEAN_READS/${b}_2.fastq
done

#ASSEMBLY
#Most computationally- and time-intensive step; uses meta-spades but can use megahit

#Concatenate all samples into one .fastq file before assembly:
cat CLEAN_READS/*_1.fastq > CLEAN_READS/ALL_READS_1.fastq
cat CLEAN_READS/*_2.fastq > CLEAN_READS/ALL_READS_2.fastq

nohup metawrap assembly -1 CLEAN_READS/ALL_READS_1.fastq -2 CLEAN_READS/ALL_READS_2.fastq -m 2000 -t 60 --metaspades -o ASSEMBLY

#KRAKEN2
#download taxonomy and build libraries based on project before running this step. I used archaea, bacteria, UniVec_Core, viral
nohup metawrap kraken2 -o KRAKEN -t 60 -s 1000000 CLEAN_READS/*.fastq ASSEMBLY/final_assembly.fasta

#BLOBOLOGY
nohup metawrap blobology -a ASSEMBLY/final_assembly.fasta -t 32 -o BLOBOLOGY --bins BIN_REFINEMENT/metawrap_70_5_bins CLEAN_READS/*.fastq

#INITIAL BINNING
#binning with three methods; results will be combined with metawrap's own algorithm later in pipeline
mkdir INITIAL_BINNING
nohup metawrap binning -o INITIAL_BINNING -t 60 -m 2000 -a ASSEMBLY/final_assembly.fasta --metabat2 CLEAN_READS/*.fastq
nohup metawrap binning -o INITIAL_BINNING -t 60 -m 2000 -a ASSEMBLY/final_assembly.fasta --maxbin2 CLEAN_READS/*.fastq
nohup metawrap binning -o INITIAL_BINNING -t 60 -m 2000 -a ASSEMBLY/final_assembly.fasta --concoct CLEAN_READS/*.fastq

#CheckM database configuration:
mkdir MY_CHECKM_FOLDER
#Manually download the database:
cd MY_CHECKM_FOLDER
wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz
tar -xvf *.tar.gz
rm *.gz
cd ../
checkm data setRoot /home/evogenlab/grouse_shotgun/MY_CHECKM_FOLDER

#BIN REFINEMENT
#The 70 and 5 parameters here refer to acceptable amounts of completion and contamination respectively, and these are the default values for this process.
mkdir BIN_REFINEMENT
nohup metawrap bin_refinement -o BIN_REFINEMENT -t 60 -A INITIAL_BINNING/metabat2_bins/ -B INITIAL_BINNING/maxbin2_bins/ -C INITIAL_BINNING/concoct_bins/ -c 70 -x 5

#QUANTIFY BINS
mkdir QUANT_BINS
nohup metawrap quant_bins -b BIN_REFINEMENT/metawrap_70_5_bins -o QUANT_BINS -a ASSEMBLY/final_assembly.fasta CLEAN_READS/*.fastq

#REASSEMBLE BINS
mkdir BIN_REASSEMBLY
nohup metawrap reassemble_bins -o BIN_REASSEMBLY -1 CLEAN_READS/ALL_READS_1.fastq -2 CLEAN_READS/ALL_READS_2.fastq -t 60 -m 2000 -c 70 -x 5 -b BIN_REFINEMENT/metawrap_70_5_bins

#NCBI Classification configuration
mkdir NCBI_nt
cd  NCBI_nt
wget "ftp://ftp.ncbi.nlm.nih.gov/blast/db/v4/nt_v4.*.tar.gz"
for a in nt.*.tar.gz; do tar xzf $a; done

mkdir NCBI_tax
cd NCBI_tax
wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz
tar -xvf taxdump.tar.gz

vim ~/.conda/envs/metawrap-env/bin/config-metawrap
#insert: BLASTDB=/data/grouse_shotgun/NCBI_nt; TAXDUMP=/data/grouse_shotgun/NCBI_tax

#BIN CLASSIFICATION
nohup metawrap classify_bins -b BIN_REASSEMBLY/reassembled_bins -o BIN_CLASSIFICATION -t 60

#BIN ANNOTATION
#make environment with prokka version 1.14; even metawrap 1.3.2 still calls 1.13, which has errors
mkdir FUNCT_ANNOT
conda activate prokka_env
cd /data/grouse_shotgun/sharp_grouse/BIN_REASSEMBLY/reassembled_bins
for file in *.fa
do
echo $file
prefix=${file:0:-3}
/home/evogenlab/.conda/envs/metawrap-env/bin/metawrap-scripts/shorten_contig_names.py $file > /data/grouse_shotgun/sharp_grouse/FUNCT_ANNOT/tmp_bin.fa
prokka --cpus 60 --force --outdir /data/grouse_shotgun/sharp_grouse/FUNCT_ANNOT/prokka_out/$prefix --prefix $prefix /data/grouse_shotgun/sharp_grouse/FUNCT_ANNOT/tmp_bin.fa
done
